\section{Experiences}
\label{sec:experiences}

The FHNW still has very little experience in the field of artificial intelligence on an FPGA.
Therefore the first part of the project was only about collecting information.
Because of the Xilinx hardware the research was already a bit more concrete, but nevertheless the field of AI was a very big world, still fairly unknown to us.
With the help of Youtube, other internet research and books we slowly worked our way into the unknown zone. 
With time the topic became more accessible to us, but there were still questions to which we have no sure answers yet.
For example, how good must the picture quality be? 
May pictures be used if the object is only partially in the picture?
How many pictures per object are enough?
Questions which can be answered with experience.
We have marked cut-off images in the database, kept the quality as high as possible and oriented ourselves to the sizes of other data sets on the Internet.

We also learned the hard way when choosing a camera with too little experience.
The plug and play version of a webcam sounded attractive, but turned out to be very useless for moving objects.

The Python scripts turned out to be a reasonable investment.
If we had started and stopped all throws with the Baumer application, countless empty images would have to be removed before and after the throw.
Thanks to the real-time image comparison we saved this work.
The additional effort for configuring the camera via script also benefits us in project 6.

At the end of this project, the results can be seen.
We are in possession of a litter stand, a data set with more than 15'000 images, as well as knowledge about AI.
