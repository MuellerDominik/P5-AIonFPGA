\section{Experiences}
\label{sec:experiences}

The FHNW still has very little experience in the field of artificial intelligence on an FPGA.
Therefore the first part of the project was only about collecting information.
Due to the fact that Xilinx hardware was given research could be focused on this product.
Aside from the hardware definition the field of AI was still a very big world, fairly unknown to us.
With the help of Youtube, other internet research and books we slowly worked our way into the unknown zone. 
With time the topic became more accessible to us, but there were still questions to which we have no right answers yet.
For example how good must the picture quality be? 
May pictures be used if the object is only partially in the picture?
How many pictures per object are enough?
Questions which are normally answered by experience.
From our lack of experience we have marked cut-off images in the database, kept the quality as high as possible and informed ourselves about the sizes of other data sets on the Internet.

We also learned the hard way when choosing a camera with too little experience.
The plug and play version of a webcam sounded attractive, but turned out to be useless for moving objects.

The Python scripts turned out to be a reasonable investment.
If we had started and stopped all throws with the Baumer application, countless empty images would have to be removed before and after the throw.
Thanks to the real-time image comparison we saved this work.
The additional effort for configuring the camera via script also benefits us in project 6.

At the end of this project, the results can be seen.
We are in possession of a litter stand, a data set with more than \num{15000} images, as well as knowledge about AI.
